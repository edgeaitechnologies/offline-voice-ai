# OfflineVoiceAI-Android

A lightweight, **entirely offline**, AI-powered **Speech-to-Text** (STT) and **Text-to-Speech** (TTS) library for Android.

Built on top of [Vosk](https://alphacephei.com/vosk/) (STT) and [Sherpa-ONNX](https://github.com/k2-fsa/sherpa-onnx) (TTS), abstracted behind a clean, **coroutine-friendly Kotlin API**.

---

## âœ¨ Features

- ğŸ”‡ **100% Offline** â€” No internet required after model download
- ğŸ¤ **Speech-to-Text** â€” Real-time voice recognition via Vosk
- ğŸ”Š **Text-to-Speech** â€” Natural speech synthesis via Sherpa-ONNX VITS
- âš¡ **Streamed TTS** â€” Low-latency audio playback with chunked synthesis
- ğŸ¤– **Streaming TTS** â€” Feed text token-by-token (perfect for LLM responses)
- â¹ **Auto-Stop on Silence** â€” Configurable silence timeout to automatically stop listening
- ğŸ§© **Simple API** â€” Single `VoiceAIManager` facade class
- ğŸ“¦ **Lightweight** â€” Models are NOT bundled; you choose your language/size

## ğŸ“‹ Prerequisites

- **Minimum SDK**: API 24 (Android 7.0)
- **Kotlin**: 2.0+
- **JDK**: 11+

## ğŸš€ Installation

### Step 1: Add JitPack repository

In your `settings.gradle.kts`:

```kotlin
dependencyResolutionManagement {
    repositories {
        google()
        mavenCentral()
        maven { url = uri("https://jitpack.io") }
    }
}
```

### Step 2: Add the dependency

In your app's `build.gradle.kts`:

```kotlin
dependencies {
    implementation("com.github.edgeaitechnologies:offline-voice-ai:1.1.2")
}
```

## ğŸ“¥ Model Setup

### Download Models

| Engine | Model | Size | Link |
|--------|-------|------|------|
| STT (Vosk) | `vosk-model-small-en-us` | ~40 MB | [Download](https://alphacephei.com/vosk/models) |
| TTS (Sherpa) | `vits-piper-en_US-amy-low` | ~25 MB | [Download](https://github.com/k2-fsa/sherpa-onnx/releases/tag/tts-models) |

### Place Models in Assets

1. Download and **unzip** the model archives
2. Place the unzipped folders in your app's `src/main/assets/` directory:

```
app/src/main/assets/
â”œâ”€â”€ vosk-model-small-en-us/
â”‚   â”œâ”€â”€ am/
â”‚   â”œâ”€â”€ conf/
â”‚   â”œâ”€â”€ graph/
â”‚   â””â”€â”€ ...
â””â”€â”€ vits-piper-en_US-amy-low/
    â”œâ”€â”€ model.onnx
    â”œâ”€â”€ tokens.txt
    â””â”€â”€ espeak-ng-data/
```

> **Note**: Models are extracted to internal storage on first run. Subsequent launches skip extraction automatically.

## ğŸ’» Quick Start

```kotlin
class MainActivity : AppCompatActivity() {

    private lateinit var voiceAI: VoiceAIManager

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)

        voiceAI = VoiceAIManager(applicationContext)

        // Initialize (suspend â€” call from a coroutine)
        lifecycleScope.launch {
            val ready = voiceAI.initialize(
                sttModelAssetName = "vosk-model-small-en-us",
                ttsModelAssetName = "vits-piper-en_US-amy-low"
            )

            if (ready) {
                // Start listening with auto-stop after 2 s silence
                voiceAI.startListening(
                    listener = object : VoiceAIListener {
                        override fun onSpeechRecognized(text: String) {
                            // Fires for every recognition event (partial + final)
                        }
                        override fun onPartialResult(text: String) {
                            Log.d("VoiceAI", "Partial: $text")
                        }
                        override fun onFinalResult(text: String) {
                            Log.d("VoiceAI", "Final: $text")
                        }
                        override fun onSilenceDetected() {
                            Log.d("VoiceAI", "User stopped speakingâ€¦")
                        }
                        override fun onAutoStopped() {
                            Log.d("VoiceAI", "Auto-stopped after silence")
                        }
                        override fun onListeningStateChanged(isListening: Boolean) {}
                        override fun onError(error: Throwable) {
                            Log.e("VoiceAI", "Error", error)
                        }
                    },
                    config = SttListeningConfig(
                        silenceTimeoutMs = 2000L,    // Auto-stop after 2 s silence
                        autoStopOnSilence = true      // Set to false for manual stop only
                    )
                )

                // Speak text with progress callbacks
                voiceAI.speak(
                    text = "Hello from OfflineVoiceAI!",
                    listener = object : TtsSpeakingListener {
                        override fun onStart(utteranceText: String) {
                            Log.d("VoiceAI", "Speaking: $utteranceText")
                        }
                        override fun onDone(utteranceText: String) {
                            Log.d("VoiceAI", "Done speaking")
                        }
                        override fun onError(utteranceText: String, error: Throwable) {
                            Log.e("VoiceAI", "TTS error", error)
                        }
                    }
                )
            }
        }
    }

    override fun onDestroy() {
        super.onDestroy()
        voiceAI.destroy() // Release native resources
    }
}
```

## ğŸ” Permissions

The library declares `RECORD_AUDIO` in its manifest (auto-merges into your app). You must **request runtime permission** before calling `startListening()`:

```kotlin
ActivityCompat.requestPermissions(
    this,
    arrayOf(Manifest.permission.RECORD_AUDIO),
    REQUEST_CODE
)
```

If permission is not granted, `VoiceAIListener.onError()` will receive a `SecurityException`.

## â¹ STT Auto-Stop on Silence

By default, the STT engine **automatically stops listening** when the user stops speaking. This is controlled via `SttListeningConfig`:

```kotlin
// Default: auto-stop after 2 seconds of silence
voiceAI.startListening(listener)

// Custom timeout: 3 seconds
voiceAI.startListening(listener, SttListeningConfig(silenceTimeoutMs = 3000L))

// Disable auto-stop (manual stop only â€” original behaviour)
voiceAI.startListening(listener, SttListeningConfig(autoStopOnSilence = false))
```

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `silenceTimeoutMs` | `Long` | `2000` | Milliseconds of silence before auto-stop |
| `autoStopOnSilence` | `Boolean` | `true` | Enable/disable auto-stop |

## ğŸ¤ STT Callbacks

All callbacks are delivered via `VoiceAIListener`. New callbacks have **default no-op implementations**, so existing code continues to work without changes.

| Callback | When it fires |
|----------|---------------|
| `onSpeechRecognized(text)` | Every recognition event (partial + final) â€” **backward compatible** |
| `onPartialResult(text)` | Real-time partial hypothesis while user is speaking |
| `onFinalResult(text)` | Confirmed final result for an utterance |
| `onSilenceDetected()` | Silence first detected after speech (timeout countdown starts) |
| `onAutoStopped()` | Engine auto-stopped due to silence timeout |
| `onListeningStateChanged(isListening)` | Microphone started/stopped recording |
| `onError(error)` | An error occurred during STT |

## ğŸ”Š TTS Speaking Callbacks

Track the lifecycle of each `speak()` call using `TtsSpeakingListener`:

| Callback | When it fires |
|----------|---------------|
| `onStart(utteranceText)` | Audio playback has begun |
| `onDone(utteranceText)` | Audio playback finished successfully |
| `onError(utteranceText, error)` | Synthesis or playback failed |

All callbacks are delivered on the **main thread**, so you can update UI directly.

The listener is optional â€” `speak("Hello")` still works as a fire-and-forget call.

## âš¡ Streamed TTS â€” Low-Latency Playback

`speakStreamed()` accepts the full text upfront but starts playing audio **immediately** as chunks are generated, rather than waiting for complete synthesis. This significantly reduces time-to-first-audio.

```kotlin
voiceAI.speakStreamed(
    text = "This will start playing much faster than speak()!",
    callback = object : TtsStreamingCallback {
        override fun onStreamingStarted() {
            Log.d("VoiceAI", "Streaming started")
        }
        override fun onSentenceSynthesized(sentence: String) {
            Log.d("VoiceAI", "Played: $sentence")
        }
        override fun onStreamingComplete() {
            Log.d("VoiceAI", "Streaming complete")
        }
        override fun onStreamingError(error: Throwable) {
            Log.e("VoiceAI", "Stream error", error)
        }
    }
)
```

## ğŸ¤– Streaming TTS â€” Incremental Text (LLM Integration)

Feed text **token-by-token** using a session-based API. Perfect for streaming LLM responses where you receive text gradually.

Text is buffered internally and split at sentence boundaries (`. ! ? \n`). Each complete sentence is synthesized and played sequentially.

```kotlin
// 1. Open a streaming session
voiceAI.beginStreaming(callback = object : TtsStreamingCallback {
    override fun onStreamingStarted() { /* session opened */ }
    override fun onSentenceSynthesized(sentence: String) {
        Log.d("VoiceAI", "Spoke: $sentence")
    }
    override fun onStreamingComplete() { /* all done */ }
    override fun onStreamingError(error: Throwable) { /* handle error */ }
})

// 2. Feed tokens as they arrive from your LLM
voiceAI.streamText("Hello ")
voiceAI.streamText("world. ")      // â† "Hello world." detected â†’ synthesized & played
voiceAI.streamText("How are ")
voiceAI.streamText("you?")          // â† "How are you?" detected â†’ queued for playback

// 3. Signal no more text
voiceAI.endStreaming()               // flushes remaining text, onStreamingComplete fires
```

### TTS Mode Comparison

| Method | Text Input | Audio Output | Best For |
|--------|-----------|--------------|----------|
| `speak(text)` | Full text at once | Waits for full synthesis | Simple one-shot TTS |
| `speakStreamed(text)` | Full text at once | Plays as chunks arrive | Low-latency TTS |
| `beginStreaming()` â†’ `streamText()` â†’ `endStreaming()` | Token-by-token | Sentence-by-sentence | LLM streaming responses |

### TtsStreamingCallback

| Callback | When it fires |
|----------|---------------|
| `onStreamingStarted()` | Streaming pipeline opened |
| `onSentenceSynthesized(sentence)` | A sentence was synthesized and played |
| `onStreamingComplete()` | All text fully spoken |
| `onStreamingError(error)` | Error during streaming |

> **Note**: `stopSpeaking()` works for all TTS modes â€” it cancels `speak()`, `speakStreamed()`, or an active streaming session.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Your Application                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       VoiceAIManager (Facade)              â”‚
â”‚  speak Â· speakStreamed Â· beginStreaming     â”‚
â”‚  streamText Â· endStreaming Â· stopSpeaking   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  SttEngine       â”‚  TtsEngine              â”‚
â”‚  (Vosk Wrapper)  â”‚  (Sherpa-ONNX Wrapper)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Vosk C++/JNI    â”‚  Sherpa-ONNX C++/JNI    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“„ License

This project is open source. See the [LICENSE](LICENSE) file for details.


